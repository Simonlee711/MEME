{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cdfe9b-3248-4257-8777-320411a5083e",
   "metadata": {},
   "source": [
    "# Notebook that handles fine-tuning from start to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2d0d69-8883-460f-9d43-ed584c3b8628",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker>=2.140.0\n",
      "  Downloading sagemaker-2.185.0.tar.gz (884 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m884.9/884.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==4.26.1\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting datasets[s3]==2.10.1\n",
      "  Using cached datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (5.4.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (23.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (1.23.5)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (2023.1.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (1.5.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (11.0.0)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.70.14)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.4.2)\n",
      "Collecting attrs<24,>=23.1.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting boto3<2.0,>=1.26.131\n",
      "  Downloading boto3-1.28.47-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (3.20.2)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (4.13.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.7.5)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Collecting jsonschema\n",
      "  Using cached jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
      "Collecting platformdirs\n",
      "  Using cached platformdirs-3.10.0-py3-none-any.whl (17 kB)\n",
      "Collecting tblib==1.7.0\n",
      "  Using cached tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.140.0) (0.6.0)\n",
      "Collecting botocore<1.32.0,>=1.31.47\n",
      "  Downloading botocore-1.31.47-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets[s3]==2.10.1) (2.1.1)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.140.0) (3.13.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (2022.12.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from google-pasta->sagemaker>=2.140.0) (1.16.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.10.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting referencing>=0.28.4\n",
      "  Using cached referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets[s3]==2.10.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets[s3]==2.10.1) (2022.7.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker>=2.140.0) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker>=2.140.0) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.9/site-packages (from schema->sagemaker>=2.140.0) (21.6.0)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.185.0-py2.py3-none-any.whl size=1185847 sha256=5cddf120f12b42a51ee3c389195c871e21cf065bd7f5516e45f0186402573c96\n",
      "  Stored in directory: /root/.cache/pip/wheels/fa/b0/ba/35ef8382d01c25c56876aad95322ec87ac97f2750cff4e4476\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: tokenizers, xxhash, tblib, rpds-py, regex, pyyaml, platformdirs, multidict, frozenlist, filelock, attrs, async-timeout, yarl, responses, referencing, huggingface-hub, botocore, aiosignal, transformers, jsonschema-specifications, aiohttp, jsonschema, boto3, sagemaker, datasets\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.70\n",
      "    Uninstalling botocore-1.29.70:\n",
      "      Successfully uninstalled botocore-1.29.70\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.70\n",
      "    Uninstalling boto3-1.26.70:\n",
      "      Successfully uninstalled boto3-1.26.70\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.132.0\n",
      "    Uninstalling sagemaker-2.132.0:\n",
      "      Successfully uninstalled sagemaker-2.132.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.70 requires botocore==1.29.70, but you have botocore 1.31.47 which is incompatible.\n",
      "awscli 1.27.70 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 boto3-1.28.47 botocore-1.31.47 datasets-2.10.1 filelock-3.12.4 frozenlist-1.4.0 huggingface-hub-0.17.1 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 multidict-6.0.4 platformdirs-3.10.0 pyyaml-6.0.1 referencing-0.30.2 regex-2023.8.8 responses-0.18.0 rpds-py-0.10.3 sagemaker-2.185.0 tblib-1.7.0 tokenizers-0.13.3 transformers-4.26.1 xxhash-3.3.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" --upgrade\n",
    "# !pip install accelerate==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73ef536-b378-41a3-81ae-322c59b7057c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO # Python 3.\n",
    "from datasets import load_dataset,Dataset,DatasetDict,concatenate_datasets\n",
    "\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#from models.EDdisposition import EDdispositionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9b6b67-a221-49e0-b124-a17632c5d259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders:\n",
      "mimic-iv-clinical-database-demo-2.2/\n",
      "mimic-iv-2.2/\n",
      "mimic-iv-ed-2.2/\n",
      "mimic-iv-ed-demo-2.2/\n"
     ]
    }
   ],
   "source": [
    "# reads out files\n",
    "\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('chianglab-dataderivatives')\n",
    "\n",
    "folders = set()\n",
    "\n",
    "for obj in bucket.objects.all():\n",
    "    prefix, delimiter, _ = obj.key.rpartition('/')\n",
    "    if prefix:\n",
    "        folders.add(prefix + '/')\n",
    "\n",
    "print('Folders:')\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd74a89c-ea6b-4550-9887-4a94a8eff1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mimic-iv-ed-2.2/\n",
      "mimic-iv-ed-2.2/text_repr.json\n",
      "['', '']\n"
     ]
    }
   ],
   "source": [
    "bucket = 'chianglab-dataderivatives'\n",
    "subfolder = 'mimic-iv-ed-2.2/'\n",
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=bucket, Prefix=subfolder)['Contents']\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for f in contents:\n",
    "    print(f['Key'])\n",
    "    file_list.append(f['Key'][36:])\n",
    "\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552fe514-9801-427b-a41c-a1147cf11d8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data we will be working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ea2dc7-0f30-4c0e-8bf1-164023eff1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataframe: 210\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival</th>\n",
       "      <th>eddischarge</th>\n",
       "      <th>admission</th>\n",
       "      <th>discharge</th>\n",
       "      <th>triage</th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>pyxis</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37887480</th>\n",
       "      <td>Patient 10014729, a 21 year old white - other ...</td>\n",
       "      <td>The ED disposition was admitted at 2125-03-19 ...</td>\n",
       "      <td>The patient was admitted at 2125-03-19 16:58:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 99.1, pulse was 90....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2125-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2154-02-05 ...</td>\n",
       "      <td>The patient was admitted at 2154-02-05 21:58:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 97.7, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103106</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>The ED disposition was home at 2154-08-03 22:2...</td>\n",
       "      <td>The patient was not admitted.</td>\n",
       "      <td>The patient was not admitted.</td>\n",
       "      <td>At triage: temperature was 96.2, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797992</th>\n",
       "      <td>Patient 10020640, a 91 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2153-02-13 ...</td>\n",
       "      <td>The patient was admitted at 2153-02-13 00:22:00.</td>\n",
       "      <td>The patient's discharge disposition was: skill...</td>\n",
       "      <td>At triage: temperature was 99.2, pulse was 130...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2153-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33473053</th>\n",
       "      <td>Patient 10015272, a 78 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2137-06-12 ...</td>\n",
       "      <td>The patient was admitted at 2137-06-12 18:36:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 97.5, pulse was 118...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2137-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arrival  \\\n",
       "37887480  Patient 10014729, a 21 year old white - other ...   \n",
       "34176810  Patient 10018328, a 83 year old white female, ...   \n",
       "32103106  Patient 10018328, a 83 year old white female, ...   \n",
       "38797992  Patient 10020640, a 91 year old white female, ...   \n",
       "33473053  Patient 10015272, a 78 year old white female, ...   \n",
       "\n",
       "                                                eddischarge  \\\n",
       "37887480  The ED disposition was admitted at 2125-03-19 ...   \n",
       "34176810  The ED disposition was admitted at 2154-02-05 ...   \n",
       "32103106  The ED disposition was home at 2154-08-03 22:2...   \n",
       "38797992  The ED disposition was admitted at 2153-02-13 ...   \n",
       "33473053  The ED disposition was admitted at 2137-06-12 ...   \n",
       "\n",
       "                                                 admission  \\\n",
       "37887480  The patient was admitted at 2125-03-19 16:58:00.   \n",
       "34176810  The patient was admitted at 2154-02-05 21:58:00.   \n",
       "32103106                     The patient was not admitted.   \n",
       "38797992  The patient was admitted at 2153-02-13 00:22:00.   \n",
       "33473053  The patient was admitted at 2137-06-12 18:36:00.   \n",
       "\n",
       "                                                  discharge  \\\n",
       "37887480  The patient's discharge disposition was: home ...   \n",
       "34176810  The patient's discharge disposition was: home ...   \n",
       "32103106                      The patient was not admitted.   \n",
       "38797992  The patient's discharge disposition was: skill...   \n",
       "33473053  The patient's discharge disposition was: home ...   \n",
       "\n",
       "                                                     triage  \\\n",
       "37887480  At triage: temperature was 99.1, pulse was 90....   \n",
       "34176810  At triage: temperature was 97.7, pulse was 74....   \n",
       "32103106  At triage: temperature was 96.2, pulse was 74....   \n",
       "38797992  At triage: temperature was 99.2, pulse was 130...   \n",
       "33473053  At triage: temperature was 97.5, pulse was 118...   \n",
       "\n",
       "                                                   medrecon  \\\n",
       "37887480  The patient was previously taking the followin...   \n",
       "34176810  The patient was previously taking the followin...   \n",
       "32103106  The patient was previously taking the followin...   \n",
       "38797992  The patient was previously taking the followin...   \n",
       "33473053  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "37887480  The patient had the following vitals: At 2125-...   \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "32103106  The patient had the following vitals: At 2154-...   \n",
       "38797992  The patient had the following vitals: At 2153-...   \n",
       "33473053  The patient had the following vitals: At 2137-...   \n",
       "\n",
       "                                                      pyxis  \\\n",
       "37887480  The patient received the following medications...   \n",
       "34176810                                                NaN   \n",
       "32103106  The patient received the following medications...   \n",
       "38797992  The patient received the following medications...   \n",
       "33473053  The patient received the following medications...   \n",
       "\n",
       "                                                      codes  \n",
       "37887480  The patient received the following diagnostic ...  \n",
       "34176810  The patient received the following diagnostic ...  \n",
       "32103106  The patient received the following diagnostic ...  \n",
       "38797992  The patient received the following diagnostic ...  \n",
       "33473053  The patient received the following diagnostic ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-ed-demo-2.2/text_repr.json\"\n",
    "\n",
    "\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "df = pd.DataFrame(json_content).T\n",
    "print(\"length of dataframe: \"+ str(len(df)))\n",
    "df.head(5)\n",
    "# df['codes_headline'] = df['ID'].map(json_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4b0f90-7596-4d53-8334-8bb0c6695f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival</th>\n",
       "      <th>triage</th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>pyxis</th>\n",
       "      <th>codes</th>\n",
       "      <th>eddischarge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37887480</th>\n",
       "      <td>Patient 10014729, a 21 year old white - other ...</td>\n",
       "      <td>At triage: temperature was 99.1, pulse was 90....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2125-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 97.7, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient did not receive any medications.</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103106</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 96.2, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797992</th>\n",
       "      <td>Patient 10020640, a 91 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 99.2, pulse was 130...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2153-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33473053</th>\n",
       "      <td>Patient 10015272, a 78 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 97.5, pulse was 118...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2137-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30272878</th>\n",
       "      <td>Patient 10038999, a 45 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was not recorded, pulse...</td>\n",
       "      <td>The patient was previously not taking any medi...</td>\n",
       "      <td>The patient had the following vitals: At 2131-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31628990</th>\n",
       "      <td>Patient 10009049, a 56 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was 99.0, pulse was 87....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2174-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32405286</th>\n",
       "      <td>Patient 10004457, a 65 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was 97.6, pulse was 103...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2141-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34391979</th>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was not recorded, pulse...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2186-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34161260</th>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was 97.0, pulse was 106...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2183-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arrival  \\\n",
       "37887480  Patient 10014729, a 21 year old white - other ...   \n",
       "34176810  Patient 10018328, a 83 year old white female, ...   \n",
       "32103106  Patient 10018328, a 83 year old white female, ...   \n",
       "38797992  Patient 10020640, a 91 year old white female, ...   \n",
       "33473053  Patient 10015272, a 78 year old white female, ...   \n",
       "...                                                     ...   \n",
       "30272878  Patient 10038999, a 45 year old white male, ar...   \n",
       "31628990  Patient 10009049, a 56 year old white male, ar...   \n",
       "32405286  Patient 10004457, a 65 year old white male, ar...   \n",
       "34391979  Patient 10004720, a 61 year old white male, ar...   \n",
       "34161260  Patient 10004720, a 61 year old white male, ar...   \n",
       "\n",
       "                                                     triage  \\\n",
       "37887480  At triage: temperature was 99.1, pulse was 90....   \n",
       "34176810  At triage: temperature was 97.7, pulse was 74....   \n",
       "32103106  At triage: temperature was 96.2, pulse was 74....   \n",
       "38797992  At triage: temperature was 99.2, pulse was 130...   \n",
       "33473053  At triage: temperature was 97.5, pulse was 118...   \n",
       "...                                                     ...   \n",
       "30272878  At triage: temperature was not recorded, pulse...   \n",
       "31628990  At triage: temperature was 99.0, pulse was 87....   \n",
       "32405286  At triage: temperature was 97.6, pulse was 103...   \n",
       "34391979  At triage: temperature was not recorded, pulse...   \n",
       "34161260  At triage: temperature was 97.0, pulse was 106...   \n",
       "\n",
       "                                                   medrecon  \\\n",
       "37887480  The patient was previously taking the followin...   \n",
       "34176810  The patient was previously taking the followin...   \n",
       "32103106  The patient was previously taking the followin...   \n",
       "38797992  The patient was previously taking the followin...   \n",
       "33473053  The patient was previously taking the followin...   \n",
       "...                                                     ...   \n",
       "30272878  The patient was previously not taking any medi...   \n",
       "31628990  The patient was previously taking the followin...   \n",
       "32405286  The patient was previously taking the followin...   \n",
       "34391979  The patient was previously taking the followin...   \n",
       "34161260  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "37887480  The patient had the following vitals: At 2125-...   \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "32103106  The patient had the following vitals: At 2154-...   \n",
       "38797992  The patient had the following vitals: At 2153-...   \n",
       "33473053  The patient had the following vitals: At 2137-...   \n",
       "...                                                     ...   \n",
       "30272878  The patient had the following vitals: At 2131-...   \n",
       "31628990  The patient had the following vitals: At 2174-...   \n",
       "32405286  The patient had the following vitals: At 2141-...   \n",
       "34391979  The patient had the following vitals: At 2186-...   \n",
       "34161260  The patient had the following vitals: At 2183-...   \n",
       "\n",
       "                                                      pyxis  \\\n",
       "37887480  The patient received the following medications...   \n",
       "34176810       The patient did not receive any medications.   \n",
       "32103106  The patient received the following medications...   \n",
       "38797992  The patient received the following medications...   \n",
       "33473053  The patient received the following medications...   \n",
       "...                                                     ...   \n",
       "30272878  The patient received the following medications...   \n",
       "31628990  The patient received the following medications...   \n",
       "32405286  The patient received the following medications...   \n",
       "34391979  The patient received the following medications...   \n",
       "34161260  The patient received the following medications...   \n",
       "\n",
       "                                                      codes  eddischarge  \n",
       "37887480  The patient received the following diagnostic ...            1  \n",
       "34176810  The patient received the following diagnostic ...            1  \n",
       "32103106  The patient received the following diagnostic ...            0  \n",
       "38797992  The patient received the following diagnostic ...            1  \n",
       "33473053  The patient received the following diagnostic ...            1  \n",
       "...                                                     ...          ...  \n",
       "30272878  The patient received the following diagnostic ...            1  \n",
       "31628990  The patient received the following diagnostic ...            1  \n",
       "32405286  The patient received the following diagnostic ...            1  \n",
       "34391979  The patient received the following diagnostic ...            1  \n",
       "34161260  The patient received the following diagnostic ...            0  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['eddischarge'] = [1 if 'admitted' in s.lower() else 0 for s in df['eddischarge']] # admitted = 1, Home = 0\n",
    "df['medrecon'] = df['medrecon'].fillna(\"The patient was previously not taking any medications.\")\n",
    "df['pyxis'] = df['pyxis'].fillna(\"The patient did not receive any medications.\")\n",
    "df['vitals'] = df['vitals'].fillna(\"The patient had no vitals recorded\")\n",
    "df['codes'] = df['codes'].fillna(\"The patient received no diagnostic codes\")\n",
    "df = df.drop(\"admission\",axis=1)\n",
    "df = df.drop(\"discharge\",axis=1)\n",
    "# df = df.drop(\"eddischarge_category\",axis=1)\n",
    "df = df[[col for col in df.columns if col != 'eddischarge'] + ['eddischarge']] # rearrange column to the end\n",
    "df['ID'] = df.arrival.astype(str).str.split().str[1].replace(\",\", \" \", regex=True).to_list()\n",
    "patient_IDS = df['ID'].to_list()\n",
    "df = df.drop(\"ID\",axis=1)\n",
    "df\n",
    "\n",
    "# remove admission and discharge columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b390118-36e6-494b-849a-e34fb4b3d8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split dataframe here\n",
    "def train_validate_test_split(df, train_percent=.7, validate_percent=.15, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    df = df.reset_index()\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    train = train.set_index('index')\n",
    "    validate = validate.set_index('index')\n",
    "    test = test.set_index('index')\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a163469-b787-4577-81f8-126e8c258769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70% Train: 360017 \n",
      "30% Test: 40002\n"
     ]
    }
   ],
   "source": [
    "t, val, t2 = train_validate_test_split(df, train_percent=.9, validate_percent=.05, seed=7)\n",
    "print(\"70% Train:\",len(t), \"\\n30% Test:\",len(val+t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c83426a4-5bfe-4cd1-8803-ab6625ee914e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 82805\n",
      "The lists are not identical\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# check that seeding works across different notebooks by reading in the test_patients.txt and seeing if they match\n",
    "test_patients = t2.arrival.astype(str).str.split().str[1].to_list()\n",
    "validate_patients = val.arrival.astype(str).str.split().str[1].to_list()\n",
    "test_patients = (test_patients+validate_patients)\n",
    "test_patients = [''.join(char for char in item if char not in string.punctuation) for item in test_patients]\n",
    "test_patients = list(set(test_patients))\n",
    "test_patients.sort()\n",
    "\n",
    "\n",
    "# extract test patient IDs into list\n",
    "f = open(\"./models/data/test_patients.txt\", \"r\")\n",
    "data = f.read()\n",
    "test_patients2 = data.split(\"\\n\")\n",
    "test_patients2.sort()\n",
    "test_patients2.pop(0) # need to pop the empty newline character\n",
    "f.close()\n",
    "\n",
    "print(len(test_patients), len(test_patients2))\n",
    "\n",
    "# using == to check if lists are equal\n",
    "if test_patients == test_patients2:\n",
    "    print(\"The lists are identical\")\n",
    "else:\n",
    "    print(\"The lists are not identical\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "597af79e-9cfb-43ad-ae7c-ef221cfc803d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of validation + test after concat:  40002\n",
      "70% Train: 28001 \n",
      "30% Test: 12001\n"
     ]
    }
   ],
   "source": [
    "remain = pd.concat([val, t2])\n",
    "print(\"Size of validation + test after concat: \", len(remain)) # sanity check\n",
    "\n",
    "# #resplit the our testing dataframe into an additional train and test split for fine tuning \n",
    "train, validate, test =  train_validate_test_split(remain, seed=7)\n",
    "print(\"70% Train:\",len(train), \"\\n30% Test:\",len(validate+test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e75041-3f38-41ce-8e3f-a447c0dd4eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we stack and unstack later for easier tokenization\n",
    "run=False\n",
    "if run:\n",
    "    disposition_train = train.eddischarge\n",
    "    temp = train.drop(\"eddischarge\",axis=1)\n",
    "    train_stack = temp.stack().to_frame(\"headline\")\n",
    "    disposition_validation = validate.eddischarge\n",
    "    temp = validate.drop(\"eddischarge\",axis=1)\n",
    "    validate_stack = temp.stack().to_frame(\"headline\")\n",
    "    disposition_test = test.eddischarge\n",
    "    temp = test.drop(\"eddischarge\",axis=1)\n",
    "    test_stack = temp.stack().to_frame(\"headline\")\n",
    "\n",
    "    training_data_corpus = Dataset.from_pandas(train_stack)\n",
    "    validation_data_corpus = Dataset.from_pandas(validate_stack)\n",
    "    test_data_corpus = Dataset.from_pandas(test_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaafff62-cc5b-429f-8f8d-41ea8424168d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cut(df, set_type):\n",
    "    col_names = df.columns.drop(\"eddischarge\")\n",
    "    l = []\n",
    "    for i in col_names:\n",
    "        temp = df[[i, 'eddischarge']].reset_index()\n",
    "        temp = temp.sort_values(by=['index']).reset_index() # we sort the patient ID numerically before dropping it to preserve order in encoding\n",
    "        temp = temp.drop(columns=[\"index\", \"level_0\"])\n",
    "        temp = temp.rename(columns={i: \"headline\", \"eddischarge\": \"label\"})\n",
    "        l.append(temp)\n",
    "        print(\"\\\"\"+i+ \"\\\" Dataframe:\", set_type, \"set has been split\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a2f8a9-cdc0-440c-98e1-587f2cc3614a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "\"arrival\" Dataframe: train set has been split\n",
      "\"triage\" Dataframe: train set has been split\n",
      "\"medrecon\" Dataframe: train set has been split\n",
      "\"vitals\" Dataframe: train set has been split\n",
      "\"pyxis\" Dataframe: train set has been split\n",
      "\"codes\" Dataframe: train set has been split\n",
      "################################################\n",
      "\"arrival\" Dataframe: validation set has been split\n",
      "\"triage\" Dataframe: validation set has been split\n",
      "\"medrecon\" Dataframe: validation set has been split\n",
      "\"vitals\" Dataframe: validation set has been split\n",
      "\"pyxis\" Dataframe: validation set has been split\n",
      "\"codes\" Dataframe: validation set has been split\n",
      "################################################\n",
      "\"arrival\" Dataframe: test set has been split\n",
      "\"triage\" Dataframe: test set has been split\n",
      "\"medrecon\" Dataframe: test set has been split\n",
      "\"vitals\" Dataframe: test set has been split\n",
      "\"pyxis\" Dataframe: test set has been split\n",
      "\"codes\" Dataframe: test set has been split\n",
      "################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"################################################\")\n",
    "l1 = cut(train, \"train\")\n",
    "print(\"################################################\")\n",
    "l2 = cut(validate, \"validation\")\n",
    "print(\"################################################\")\n",
    "l3 = cut (test, \"test\")\n",
    "print(\"################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18be215f-7016-4d47-b2e5-79c2f79c01e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# tokenize\n",
    "model = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "class Tokenizer():\n",
    "    def tokenize(self,examples):\n",
    "      \"\"\"Mapping function to tokenize the sentences passed with truncation\"\"\"\n",
    "      return tokenizer(examples[\"headline\"], truncation=True, padding=\"max_length\",\n",
    "                        max_length=512, return_special_tokens_mask=True)\n",
    "    def convert(self, l):\n",
    "        \"\"\"\n",
    "        Run this method\n",
    "        \"\"\"\n",
    "        arrival_hf=Dataset.from_pandas(l[0])\n",
    "        triage_hf=Dataset.from_pandas(l[1])\n",
    "        medrecon_hf=Dataset.from_pandas(l[2])\n",
    "        vitals_hf=Dataset.from_pandas(l[3])\n",
    "        codes_hf=Dataset.from_pandas(l[4])\n",
    "        pyxis_hf=Dataset.from_pandas(l[5])\n",
    "\n",
    "        arrival = arrival_hf.map(self.tokenize, batched=True)\n",
    "        triage = triage_hf.map(self.tokenize, batched=True)\n",
    "        medrecon = medrecon_hf.map(self.tokenize, batched=True)\n",
    "        vitals = vitals_hf.map(self.tokenize, batched=True)\n",
    "        codes = codes_hf.map(self.tokenize, batched=True)\n",
    "        pyxis = pyxis_hf.map(self.tokenize, batched=True)\n",
    "\n",
    "        arrival.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "        triage.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "        medrecon.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "        vitals.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "        codes.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "        pyxis.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "\n",
    "        return arrival, triage, medrecon, vitals, codes, pyxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b808e7e8-77f0-4bda-a431-25fa019b0bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "# calls methods and tokenizes text\n",
    "processor = Tokenizer()\n",
    "arrival_train_tokens, triage_train_tokens, medrecon_train_tokens, vitals_train_tokens, codes_train_tokens, pyxis_train_tokens, = processor.convert(l1)\n",
    "arrival_val_tokens, triage_val_tokens, medrecon_val_tokens, vitals_val_tokens, codes_val_tokens, pyxis_val_tokens, = processor.convert(l2)\n",
    "arrival_test_tokens, triage_test_tokens, medrecon_test_tokens, vitals_test_tokens, codes_test_tokens, pyxis_test_tokens, = processor.convert(l3)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "176b7539-896a-47b1-966a-3ca46ba2cab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arrival_dataset_cc = DatasetDict({\n",
    "    'train': arrival_train_tokens,\n",
    "    'test': arrival_test_tokens,\n",
    "    'valid': arrival_val_tokens})\n",
    "\n",
    "triage_dataset_cc = DatasetDict({\n",
    "    'train': triage_train_tokens,\n",
    "    'test': triage_test_tokens,\n",
    "    'valid': triage_val_tokens})\n",
    "\n",
    "medrecon_dataset_cc = DatasetDict({\n",
    "    'train': medrecon_train_tokens,\n",
    "    'test': medrecon_test_tokens,\n",
    "    'valid': medrecon_val_tokens})\n",
    "\n",
    "vitals_dataset_cc = DatasetDict({\n",
    "    'train': vitals_train_tokens,\n",
    "    'test': vitals_test_tokens,\n",
    "    'valid': vitals_val_tokens})\n",
    "\n",
    "codes_dataset_cc = DatasetDict({\n",
    "    'train': codes_train_tokens,\n",
    "    'test': codes_test_tokens,\n",
    "    'valid': codes_val_tokens})\n",
    "\n",
    "pyxis_dataset_cc = DatasetDict({\n",
    "    'train': pyxis_train_tokens,\n",
    "    'test': pyxis_test_tokens,\n",
    "    'valid': pyxis_val_tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88afb86f-43a1-4674-ae38-a422798089cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader_concat = [triage_dataset_cc[\"train\"], arrival_dataset_cc[\"train\"],medrecon_dataset_cc[\"train\"],vitals_dataset_cc[\"train\"],codes_dataset_cc[\"train\"],pyxis_dataset_cc[\"train\"]]\n",
    "valid_dataloader_concat = [triage_dataset_cc[\"valid\"], arrival_dataset_cc[\"valid\"],medrecon_dataset_cc[\"valid\"],vitals_dataset_cc[\"valid\"],codes_dataset_cc[\"valid\"],pyxis_dataset_cc[\"valid\"]]\n",
    "test_dataloader_concat = [triage_dataset_cc[\"test\"], arrival_dataset_cc[\"test\"],medrecon_dataset_cc[\"test\"],vitals_dataset_cc[\"test\"],codes_dataset_cc[\"test\"],pyxis_dataset_cc[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "470c8121-24d3-49e2-a73c-fd381ced0fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EDdispositionClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A task-specific custom transformer model for predicting ED Disposition. \n",
    "    This model loads a pre-trained transformer model and adds a new dropout \n",
    "    and linear layer at the end for fine-tuning and prediction on specific tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint, num_labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            checkpoint (str): The name of the pre-trained model or path to the model weights.\n",
    "            num_labels (int): The number of output labels in the final classification layer.\n",
    "        \"\"\"\n",
    "        super(EDdispositionClassifier, self).__init__()\n",
    "        self.num_labels = num_labels # number of labels for classifier\n",
    "        \n",
    "        # checkpoint is the model name \n",
    "        self.model = model = AutoModel.from_pretrained(checkpoint, config = AutoConfig.from_pretrained(checkpoint, \n",
    "                                                                                                       output_attention = True, \n",
    "                                                                                                       output_hidden_state = True ) )\n",
    "        # New Layer\n",
    "        self.dropout = nn.Dropout(0.1) # to prevent overfittting\n",
    "        self.classifier = nn.Linear(768, num_labels) #FC Layer - takes in a 768 token vector and is a Linear classifier with n labels\n",
    "        \n",
    "    def forward(self, input_ids = None, attention_mask=None, labels = None ):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "        \n",
    "        Args:\n",
    "            input_ids (torch.Tensor, optional): Tensor of input IDs. Defaults to None.\n",
    "            attention_mask (torch.Tensor, optional): Tensor for attention masks. Defaults to None.\n",
    "            labels (torch.Tensor, optional): Tensor for labels. Defaults to None.\n",
    "            \n",
    "        Returns:\n",
    "            TokenClassifierOutput: A named tuple with the following fields:\n",
    "            - loss (torch.FloatTensor of shape (1,), optional, returned when label_ids is provided) – Classification loss.\n",
    "            - logits (torch.FloatTensor of shape (batch_size, num_labels)) – Classification scores before SoftMax.\n",
    "            - hidden_states (tuple(torch.FloatTensor), optional, returned when output_hidden_states=True is passed or when config.output_hidden_states=True) – Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
    "            - attentions (tuple(torch.FloatTensor), optional, returned when output_attentions=True is passed or when config.output_attentions=True) – Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).\n",
    "        \"\"\"\n",
    "        # calls on the Automodel to deploy correct model - in our case distilled-bert-uncased\n",
    "        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask  )\n",
    "        \n",
    "        # retrieves the last hidden state\n",
    "        last_hidden_state = outputs[0]\n",
    "        \n",
    "        return last_hidden_state # The embedding\n",
    "        \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_layers=6, d_model=768, nhead=8, dim_feedforward=2048):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.num_labels = 2 # number of labels for classifier\n",
    "        self.dropout = nn.Dropout(0.1) # to prevent overfittting\n",
    "        self.classifier = nn.Linear(768, 2) #FC Layer - takes in a 768 token vector and is a Linear classifier with n labels\n",
    "        self.dense_layer = nn.Linear(768, 768)\n",
    "\n",
    "    def forward(self, src, labels=None, attention=True):\n",
    "        if attention:\n",
    "            output = self.transformer_encoder(src)\n",
    "            # project brand new layers into 768 dimensions \n",
    "            # src = self.dense_layer(output)\n",
    "        \n",
    "        # begin classification\n",
    "        # include dropout from constructor to feed forward network\n",
    "        sequence_outputs = self.dropout(src)\n",
    "        \n",
    "        # finally add linear layer from input\n",
    "        logits = self.classifier(sequence_outputs[:, 0, : ].view(-1, 768 ))\n",
    "        \n",
    "        # calculates loss \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_func = nn.CrossEntropyLoss() # Change this if it becomes more than binary classification\n",
    "            loss = loss_func(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            \n",
    "            # TokenClassifierOutput - returns predicted label\n",
    "            return TokenClassifierOutput(loss=loss, logits=logits)#, hidden_states=outputs.hidden_states, attentions=new_vec.attentions)\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "class EDDispositionFineTuneModel(nn.Module):\n",
    "    def __init__(self, checkpoint, num_labels=2, input_dim=768, modalities=None):\n",
    "        super(EDDispositionFineTuneModel, self).__init__()\n",
    "        self.encoder = EDdispositionClassifier(checkpoint=checkpoint, num_labels=num_labels)\n",
    "        self.predictor = TransformerModel()\n",
    "        assert modalities is not None, \"Number of modalities missing\"\n",
    "        self.modalities = modalities\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, label=None):\n",
    "        # input_ids: dictionary of the batch\n",
    "        # attention_mask: dictionary of the batch\n",
    "        embedding = []\n",
    "        for modality in range(self.modalities):\n",
    "            embed = self.encoder(input_ids[modality], attention_mask[modality], label)\n",
    "            embedding.append(embed)\n",
    "        unified_embedding = torch.cat((embedding[0],embedding[1],embedding[2],embedding[3],embedding[4],embedding[5]),1) # concatenates embeddings on the second dimension\n",
    "        outputs = self.predictor(unified_embedding, label)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a905e39-f0d2-4d9c-841a-56e32ce01dca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "full_model = EDDispositionFineTuneModel(checkpoint=model, num_labels=2, input_dim=768, modalities=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "570cd4c5-135d-4c1c-b122-9fe3768456dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7ff0d57f39e0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_specific.parameters()\n",
    "predictor.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d80f7521-ac7b-4f8d-93ae-d715521f73b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get all of the model's parameters as a list of tuples.\n",
    "# params = list(model.named_parameters())\n",
    "\n",
    "# print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "# print('==== Embedding Layer ====\\n')\n",
    "\n",
    "# for p in params[0:5]:\n",
    "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "# print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "# for p in params[5:21]:\n",
    "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "# print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "# for p in params[-4:]:\n",
    "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6cfc1d4-d637-40d4-8f72-da9191b20403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "# optimizer = AdamW(model_task_specific.parameters(), lr = 5e-5 )\n",
    "optimizer = AdamW(full_model.parameters(), lr = 5e-5 )\n",
    "\n",
    "num_epoch = 2\n",
    "BATCH = 8\n",
    "num_training_steps = num_epoch * len(triage_dataset_cc['train'][\"input_ids\"]) // BATCH\n",
    "print(len(triage_dataset_cc['train'][\"input_ids\"]))\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14d113f3-ed24-43ed-b43b-e6c1cfc84b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 7.55kB [00:00, 4.06MB/s]                   \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb186332-7510-4cbb-8e7d-ddef0cde8bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [06:41<00:00, 21.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch training 0 done\n",
      "loss: tensor(0.6854, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:41<00:00, 10.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch validation 0 done\n",
      "{'precision': 0.7407407407407407}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [04:39<00:00, 14.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch training 1 done\n",
      "loss: tensor(0.6004, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:23<00:00,  5.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch validation 1 done\n",
      "{'precision': 0.7857142857142857}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [06:36<00:00, 20.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch training 2 done\n",
      "loss: tensor(0.7934, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:41<00:00, 10.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch validation 2 done\n",
      "{'precision': 0.6923076923076923}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [05:14<00:00, 16.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch training 3 done\n",
      "loss: tensor(0.7634, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:25<00:00,  6.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch validation 3 done\n",
      "{'precision': 0.625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [07:28<00:00, 23.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch training 4 done\n",
      "loss: tensor(0.7090, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch validation 4 done\n",
      "{'precision': 0.7222222222222222}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP\n",
    "num_epoch=1\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar_train = tqdm(range(num_epoch * len(triage_dataset_cc['train'][\"input_ids\"]) // BATCH ))\n",
    "# progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(triage_dataset_cc['valid'][\"input_ids\"]) // BATCH ))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    full_model.train()\n",
    "    print(f\"Epoch {epoch}...\")\n",
    "    random_idx = np.random.permutation(np.arange(len(train_dataloader_concat[0]['input_ids'])))\n",
    "    # for i, b in tqdm(enumerate(train_dl)):\n",
    "    for step, idx in enumerate(range(0, len(random_idx), BATCH)):\n",
    "        iter_rand_idx = random_idx[idx:idx+BATCH]\n",
    "        input_ids, attention_mask = [], []\n",
    "        for modality in train_dataloader_concat:\n",
    "            input_ids.append(modality['input_ids'][iter_rand_idx].to(device))\n",
    "            attention_mask.append(modality['attention_mask'][iter_rand_idx].to(device))\n",
    "        label = modality['label'][iter_rand_idx].to(device)\n",
    "        outputs = full_model(input_ids, attention_mask, label)\n",
    "#         unified_embedding = torch.cat((embedding[0],embedding[1],embedding[2],embedding[3],embedding[4],embedding[5]),1) # concatenates embeddings on the second dimension\n",
    "#         outputs = predictor(unified_embedding, modality['label'][i:i+BATCH].to(device))\n",
    "        # updates weights accordingly\n",
    "        loss = outputs.loss\n",
    "        loss.backward() # computes gradients\n",
    "\n",
    "        optimizer.step() # updates the weights and biases based on these gradients\n",
    "        lr_scheduler.step() # updates the weights and biases based on these gradients\n",
    "        optimizer.zero_grad() # used to clear the gradients of all parameters in a model\n",
    "        progress_bar_train.update(1)\n",
    "    \n",
    "    # # run on validation set\n",
    "    print(\"Validation\")\n",
    "    full_model.eval()\n",
    "    # for i, b in tqdm(enumerate(train_dl)):\n",
    "    for step, idx in enumerate(range(0, len(valid_dataloader_concat[0]['input_ids']), BATCH)):\n",
    "        input_ids, attention_mask = [], []\n",
    "        for modality in valid_dataloader_concat:\n",
    "            input_ids.append(modality['input_ids'][idx:idx+BATCH].to(device))\n",
    "            attention_mask.append(modality['attention_mask'][idx:idx+BATCH].to(device))\n",
    "        label = modality['label'][idx:idx+BATCH].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = full_model(input_ids, attention_mask, label)\n",
    "        logits = outputs.logits # calculates the probabilities between the labels\n",
    "        predictions = torch.argmax(logits, dim = -1 ) # takes the label closest to 1\n",
    "        metric.add_batch(predictions = predictions, references = label) \n",
    "        loss = outputs.loss\n",
    "        progress_bar_eval.update(1)\n",
    "    \n",
    "    print(metric.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1afd85-0cb0-4b59-988b-4eedf6722b90",
   "metadata": {},
   "source": [
    "# Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd495290-88c6-47a7-be4a-31b2548d8ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6190476190476191}\n"
     ]
    }
   ],
   "source": [
    "logit_list = []\n",
    "label_list = []\n",
    "probs_list = []\n",
    "\n",
    "full_model.eval()\n",
    "for step, idx in tqdm(enumerate(range(0, len(test_dataloader_concat[0]['input_ids']), BATCH))):\n",
    "    input_ids, attention_mask = [], []\n",
    "    for modality in test_dataloader_concat:\n",
    "        input_ids.append(modality['input_ids'][idx:idx+BATCH].to(device))\n",
    "        attention_mask.append(modality['attention_mask'][idx:idx+BATCH].to(device))\n",
    "    label = modality['label'][idx:idx+BATCH].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = full_model(input_ids, attention_mask, label)\n",
    "    logits = outputs.logits # calculates the probabilities between the labels\n",
    "    predictions = torch.argmax(logits, dim = -1 ) # takes the label closest to 1\n",
    "    loss = outputs.loss\n",
    "    logits = outputs.logits # calculates the probabilities between the labels\n",
    "    logit_list.append(logits[:, 1].cpu().detach().numpy())\n",
    "    label_list.append(label.cpu().detach().numpy())\n",
    "    probs_list.append(torch.sigmoid(logits[:, 1]).cpu().detach().numpy())\n",
    "    predictions = torch.argmax(logits, dim = -1 ) # takes the label closest to 1\n",
    "    metric.add_batch(predictions = predictions, references = label)\n",
    "    # print(\"New Batch\")\n",
    "    # print(predictions)\n",
    "    # print(modality['label'][i:i+BATCH])\n",
    "\n",
    "print(metric.compute()) "
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
